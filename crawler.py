from datetime import datetime, timedelta
from pathlib import Path
import json, os, sys, time, traceback

from crawler_utils import crawl_teescan, crawl_golfpang, GOLF_CLUBS

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR   = Path("data"); DATA_DIR.mkdir(exist_ok=True)
MAX_DAYS   = 18            # ì˜¤ëŠ˜ë¶€í„° 10ì¼ì¹˜
INTERVAL   = 9000          # 11ë¶„(ì´ˆ)
FAVORITES  = []           # ì¶”í›„ í™˜ê²½ë³€ìˆ˜ ë“±ìœ¼ë¡œ ì£¼ì… ê°€ëŠ¥

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log(msg, level="INFO"):
    ts = datetime.now().strftime("%H:%M:%S")
    print(f"[{level}] {ts}  {msg}", flush=True)

def crawl_date(date_str: str):
    try:
        items = crawl_teescan(date_str, FAVORITES) + crawl_golfpang(date_str, FAVORITES)
        (DATA_DIR / f"{date_str}.json").write_text(
            json.dumps(items, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
        log(f"{date_str}.json ì €ì¥ ì™„ë£Œ  ({len(items)}ê±´)")
    except Exception as e:
        log(f"{date_str} ìˆ˜ì§‘ ì‹¤íŒ¨ â†’ {e}", level="ERROR")
        traceback.print_exc()

def loop():
    log("í¬ë¡¤ëŸ¬ ë£¨í”„ ì‹œì‘!")
    try:
        while True:
            start_ts = time.time()

            today = datetime.now().date()
            for i in range(MAX_DAYS):
                crawl_date((today + timedelta(days=i)).strftime("%Y-%m-%d"))

            # â”€â”€ ë‹¤ìŒ ë£¨í”„ê¹Œì§€ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ë“œë¦¬í”„íŠ¸ ë°©ì§€) â”€â”€
            elapsed = time.time() - start_ts
            sleep_sec = max(0, INTERVAL - elapsed)
            log(f"ğŸ•‘ {sleep_sec:0.1f}ì´ˆ ë’¤ ë‹¤ìŒ ë¼ìš´ë“œ")
            time.sleep(sleep_sec)
    except KeyboardInterrupt:
        log("KeyboardInterrupt â†’ í¬ë¡¤ëŸ¬ ì¢…ë£Œ")
    except Exception as e:
        log(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}", level="ERROR")
        traceback.print_exc()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI ì§„ì…ì  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    if len(sys.argv) == 2:
        crawl_date(sys.argv[1])          # ì˜ˆ: python crawler.py 2025-07-15
    else:
        loop()
